{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC Edgar Data Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will analyze the SEC Edgar data. The SEC Edgar data is a dataset of financial reports of companies that are filed with the SEC. The dataset contains the following columns:\n",
    "\n",
    "- `cik`: The Central Index Key for the filing entity.\n",
    "- `name`: The name of the entity.\n",
    "- `ticker`: The ticker symbol of the entity.\n",
    "- `sic`: The Standard Industrial Classification code for the filing.\n",
    "- `adsh`: The Accession Number for the submission.\n",
    "- `countryba`: The ISO country code for the filing's business address.\n",
    "- `stprba`: The region for the filing's business address.\n",
    "- `cityba`: The city for the filing's business address.\n",
    "- `zipba`: The zip code for the filing's business address.\n",
    "- `bas1`: The street address for the filing's business address.\n",
    "- `form`: The submission type of the filing.\n",
    "- `period`: The period end date.\n",
    "- `fy`: The fiscal year end date.\n",
    "- `fp`: The fiscal period focus (Q1, Q2, Q3, FY).\n",
    "- `filed`: The date the report was filed.\n",
    "- `accepted`: The date the report was accepted.\n",
    "- `prevrpt`: The Accession Number for the previous report.\n",
    "- `detail`: The file name of the primary financial statements and notes.\n",
    "- `instance`: The file name of the XBRL instance document.\n",
    "- `nciks`: The number of additional Central Index Keys for the filing.\n",
    "- `aciks`: The number of additional Central Index Keys for the filing that are not included in the submission.\n",
    "- `year`: The year of the filing.\n",
    "- `quarter`: The quarter of the filing.\n",
    "- `month`: The month of the filing.\n",
    "- `day`: The day of the filing.\n",
    "- `hour`: The hour of the filing.\n",
    "\n",
    "We will analyze the dataset to understand the financial reports of companies that are filed with the SEC.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "We will use the following libraries in this notebook:\n",
    "\n",
    "- `pandas` for data manipulation.\n",
    "- `requests` for making HTTP requests.\n",
    "- `numpy` for numerical operations.\n",
    "- `calendar` for calendar operations.\n",
    "- `logging` for logging operations.\n",
    "- `os` for file operations.\n",
    "\n",
    "## Custom Functions\n",
    "\n",
    "We will define the following custom functions in this notebook:\n",
    "\n",
    "- `edgar_functions.py`: This file contains custom functions for analyzing the SEC Edgar data.\n",
    "- \n",
    "\n",
    "Let's load the data and take a look at the first few rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "headers = {\"User-Agent\": \"amr@bashconsultants.com\"}  # Need to add your email address here\n",
    "\n",
    "def cik_ticker(ticker, headers=headers):\n",
    "    ticker = ticker.upper().replace(\".\", \"-\")\n",
    "    ticker_json = requests.get(\n",
    "    for company in ticker_json.values():\n",
    "        \"https://www.sec.gov/files/company_tickers.json\", headers=headers\n",
    "    for company in ticker_json.value:\n",
    "    ).json()\n",
    "\n",
    "        if company[\"ticker\"] == ticker:\n",
    "            cik = str(company[\"cik_str\"]).zfill(10)\n",
    "            return cik\n",
    "\n",
    "    raise ValueError(f\"Ticker {ticker} not found in SEC database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ticker you want to get the CIK for and run the function\n",
    "\n",
    "ticker = \"ccs\"\n",
    "cik_id = cik_ticker(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the json data for the company with the CIK based on the ticker\n",
    "\n",
    "def get_submission_data_for_ticker(ticker, headers=headers, only_filings_df=False):\n",
    "    \"\"\"\n",
    "    Get the data in json form for a given ticker. For example: 'cik', 'entityType', 'sic', 'sicDescription', 'insiderTransactionForOwnerExists', 'insiderTransactionForIssuerExists', 'name', 'tickers', 'exchanges', 'ein', 'description', 'website', 'investorWebsite', 'category', 'fiscalYearEnd', 'stateOfIncorporation', 'stateOfIncorporationDescription', 'addresses', 'phone', 'flags', 'formerNames', 'filings'\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The ticker symbol of the company.\n",
    "\n",
    "    Returns:\n",
    "        json: The submissions for the company.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If ticker is not a string.\n",
    "    \"\"\"\n",
    "    cik = cik_ticker(ticker)\n",
    "    headers = headers\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    company_json = requests.get(url, headers=headers).json()\n",
    "    if only_filings_df:\n",
    "        return pd.DataFrame(company_json[\"filings\"][\"recent\"])\n",
    "    else:\n",
    "        return company_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \n",
    "submission_data = get_submission_data_for_ticker(ticker, only_filings_df=False)\n",
    "print(submission_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_json(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_json(data, cik_id, filename):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame.to_json(data)  # convert DataFrame to JSON\n",
    "    with open(f'company-{filename}-{cik_id}.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(submission_data, pd.DataFrame)\n",
    "submission_data = pd.DataFrame.to_json(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = submission_data  # replace with your actual data\n",
    "filename = \"submissions\"\n",
    "export_to_json(data_dict, cik_id, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_filings(\n",
    "    ticker, ten_k=True, just_accession_numbers=False, headers=headers\n",
    "):\n",
    "    company_filings_df = get_submission_data_for_ticker(\n",
    "        ticker, only_filings_df=True, headers=headers\n",
    "    )\n",
    "    if ten_k:\n",
    "        df = company_filings_df[company_filings_df[\"form\"] == \"10-K\"]\n",
    "    else:\n",
    "        df = company_filings_df[company_filings_df[\"form\"] == \"10-Q\"]\n",
    "    if just_accession_numbers:\n",
    "        df = df.set_index(\"reportDate\")\n",
    "        accession_df = df[\"accessionNumber\"]\n",
    "        return accession_df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filings = get_filtered_filings(ticker, ten_k=False, just_accession_numbers=True, headers=headers)\n",
    "\n",
    "filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the company based on the CIK\n",
    "\n",
    "def get_facts(ticker, headers=headers):\n",
    "    cik = cik_ticker(ticker)\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    company_facts = requests.get(url, headers=headers).json()\n",
    "    return company_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the facts for the company\n",
    "facts = get_facts(ticker)\n",
    "facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the account facts for the company for us-gaap\n",
    "\n",
    "facts[\"facts\"][\"us-gaap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_gaap_levels = facts[\"facts\"][\"us-gaap\"].keys()\n",
    "us_gaap_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the account facts to a csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('acct_facts.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write headers\n",
    "    writer.writerow([\"us_gaap_list\", \"acct_label\", \"acct_description\"])\n",
    "    \n",
    "    for us_gaap_list in facts[\"facts\"][\"us-gaap\"]:\n",
    "        acct_label = facts[\"facts\"][\"us-gaap\"][us_gaap_list][\"label\"]\n",
    "        acct_description = facts[\"facts\"][\"us-gaap\"][us_gaap_list][\"description\"]\n",
    "        print(f\"{us_gaap_list}, {acct_label}, {acct_description}\")\n",
    "        writer.writerow([us_gaap_list, acct_label, acct_description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_DF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import zipfile\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='error_log.txt', level=logging.ERROR)\n",
    "\n",
    "def facts_DF():\n",
    "    with zipfile.ZipFile('companyfacts.zip', 'r') as z:\n",
    "        for filename in z.namelist():\n",
    "            try:\n",
    "                with z.open(filename) as f:\n",
    "                    facts = json.load(f)\n",
    "                    if 'us-gaap' in facts[\"facts\"]:\n",
    "                        us_gaap_data = facts[\"facts\"][\"us-gaap\"]\n",
    "                        for fact, details in us_gaap_data.items():\n",
    "                            acct_label = details[\"label\"]\n",
    "                            acct_description = details[\"description\"]\n",
    "                            yield fact, acct_label, acct_description\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "                logging.error(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "seen = set()\n",
    "\n",
    "with open('acct_facts.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write headers\n",
    "    writer.writerow([\"us_gaap_list\", \"acct_label\", \"acct_description\"])\n",
    "    \n",
    "    json_output = []\n",
    "    \n",
    "    for us_gaap_list, acct_label, acct_description in facts_DF():\n",
    "        # Create a tuple of the row\n",
    "        row = (us_gaap_list, acct_label, acct_description)\n",
    "        # If we've already seen this row, skip it\n",
    "        if row in seen:\n",
    "            continue\n",
    "        # Add the row to the set of seen rows\n",
    "        seen.add(row)\n",
    "        print(f\"{us_gaap_list}, {acct_label}, {acct_description}\")\n",
    "        writer.writerow([us_gaap_list, acct_label, acct_description])\n",
    "        json_output.append({\n",
    "            \"us_gaap_list\": us_gaap_list,\n",
    "            \"acct_label\": acct_label,\n",
    "            \"acct_description\": acct_description\n",
    "        })\n",
    "    \n",
    "    # Write to JSON file\n",
    "    with open('acct_facts.json', 'w') as json_file:\n",
    "        json.dump(json_output, json_file, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = facts  # replace with your actual data\n",
    "filename = \"facts\"\n",
    "export_to_json(data_dict, cik_id, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facts_DF(ticker, headers=headers):\n",
    "    facts = get_facts(ticker, headers)\n",
    "    us_gaap_data = facts[\"facts\"][\"us-gaap\"]\n",
    "    df_data = []\n",
    "    for fact, details in us_gaap_data.items():\n",
    "        for unit in details[\"units\"]:\n",
    "            for item in details[\"units\"][unit]:\n",
    "                row = item.copy()\n",
    "                row[\"fact\"] = fact\n",
    "                df_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(df_data)\n",
    "    df[\"end\"] = pd.to_datetime(df[\"end\"])\n",
    "    df[\"start\"] = pd.to_datetime(df[\"start\"])\n",
    "    df = df.drop_duplicates(subset=[\"fact\", \"end\", \"val\"])\n",
    "    df.set_index(\"end\", inplace=True)\n",
    "    labels_dict = {fact: details[\"label\"] for fact, details in us_gaap_data.items()}\n",
    "    return df, labels_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
